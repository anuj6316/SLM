{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f8061fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f97023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac47360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53849e2773b45f59da533f5382d693c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a06c68da5b41b4aa7b1d9a65afb100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da517fb4529f4fa09187eee19f2edc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209b1d31e59d44cd8101f960ddcb09d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 2387, 766, 16, 660, 11591, 449, 16160, 2, 1, 1, 1, 1, 1, 1], [0, 100, 23126, 2364, 5, 6424, 11, 5, 4754, 9, 4687, 73, 10537, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"sshleifer/distilbart-cnn-12-6\", # sentiment analysis model\n",
    ")\n",
    "\n",
    "raw_inputs = [\n",
    "    \"My name is Anuj kumar\",\n",
    "    \"I wanna gain the expertise in the Field of AI/ML.\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(\n",
    "    raw_inputs,\n",
    "    padding = True,\n",
    "    truncation = True,\n",
    "    return_tensor = \"pt\"\n",
    ")\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7508ddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sentence: My name is Anuj kumar\n",
      "Tokens/Input Ids: [0, 2387, 766, 16, 660, 11591, 449, 16160, 2, 1, 1, 1, 1, 1, 1]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "Sentence length: 5\n",
      "input_ids length 15\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentence: I wanna gain the expertise in the Field of AI/ML.\n",
      "Tokens/Input Ids: [0, 100, 23126, 2364, 5, 6424, 11, 5, 4754, 9, 4687, 73, 10537, 4, 2]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Sentence length: 10\n",
      "input_ids length 15\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(f\"{raw_inputs[0]}\\nTokenizer-\\n{inputs['input_ids'][0]}\\n\")\n",
    "# print(f\"Attention Masks-\\n{inputs['attention_mask'][0]}\\n\")\n",
    "\n",
    "for i, sentence in enumerate(raw_inputs):\n",
    "    print(\"\\n\")\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Tokens/Input Ids: {inputs['input_ids'][i]}\") # token id of sentence\n",
    "    print(f\"Attention Mask: {inputs['attention_mask'][i]}\") # this tells model which token to give attention to\n",
    "    print(f\"Sentence length: {len(sentence.split(\" \"))}\\ninput_ids length {len(inputs['input_ids'][i])}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c098a4",
   "metadata": {},
   "source": [
    "## Tokenizer Under the Hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5411c1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'Ġname', 'Ġis', 'ĠAn', 'uj', 'Ġk', 'umar']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(raw_inputs[0])\n",
    "tokens ## G represents space, u continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce10dc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2387, 766, 16, 660, 11591, 449, 16160]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3982730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'My name is Anuj kumar'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_token = tokenizer.decode(token_ids)\n",
    "decode_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af97d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 2387, 766, 16, 660, 11591, 449, 16160, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_prepped_ids = tokenizer.prepare_for_model(token_ids)\n",
    "model_prepped_ids = tokenizer(raw_inputs[0])\n",
    "model_prepped_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c6c53",
   "metadata": {},
   "source": [
    "## Working with Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15b7a79",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "452619a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcd82fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7e405385ed40359248e2b67556f0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ba9f5e54144e76a6a01e86b915ea45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e63d60bdf1144b7961433fe0b3c90bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465fb8808c38405db94d45a58d3d31db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6164db23df34368aed4b9f94c2e92c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984731078147888},\n",
       " {'label': 'NEGATIVE', 'score': 0.985593855381012}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## classifier\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e52e13a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73272d71461c43abbd8bc82f02cb9785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f863ce5fdbef428dabf8631f26159c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4522b8e32c4010b51396177fdb2b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: openai-community/gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43cef05ad7e4920b3067031aa265c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92b85e4b83e46aaadee1b2e0300f2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f6976ed7274edc900889673b5ed07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53723559060487d8f4dd481b9f6529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88435f379d2e4306a2ffa24c4372fe9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': 'My name is Anuj kumar and I am the founder of the Foundation for Science and Technology (FST). I am a retired engineer at the National Science Foundation in New Delhi.\\n\\nI am also a PhD candidate at the SRI University of Technology, Mumbai.\\n\\nI am a member of the Indian Institute of Technology\\'s Board of Scientific Research (BIR) and is a member of the International Scientific Board.\\n\\nI am the principal investigator and project leader of the FST and the first research co-author. The BRI is an interdisciplinary network of scientists working together to create and develop a better understanding of the natural world.\\n\\nSince 2001, I have been awarded the BRI\\'s prestigious Distinguished Scientist Award for \"Best Scientific Research in the World\" (M.S.). The award is also given to the co-author of the book \"World\\'s Most Influential Scientists\", published in 2007 by the World Science Foundation.\\n\\nThe BRI\\'s scientific advisory council (SRI) is the body of scientific advisory boards for the major scientific institutions in the world. The SRI is responsible for defining and managing the scientific policy and policy process, promoting and protecting the integrity of the scientific method, and providing scientific education and training to the public.\\n\\nI am'}],\n",
       " [{'generated_text': \"I wanna gain the expertise in the Field of AI/ML.\\n\\nI'm looking to build a better understanding of the game.\\n\\nI want to use my knowledge to improve the game.\\n\\nI want to learn more about the game.\\n\\nI want to be a part of the community.\\n\\nI want to experience the game.\\n\\nI want to have a chance to be involved in the community.\\n\\nI want to get involved in the community.\\n\\nI want to have a chance to be involved in the community.\\n\\nI want to have a chance to be involved in the community.\\n\\nI want to be involved in the community.\\n\\nI want to know more about the game.\\n\\nI want to know more about the game.\\n\\nI want to know more about the game.\\n\\nI want to know more about the game.\\n\\nI want to be involved in the community.\\n\\nI want to have a chance to be involved in the community.\\n\\nI want to be involved in the community.\\n\\nI want to be involved in the community.\\n\\nI want to be involved in the community.\\n\\nI want to be involved in the community.\\n\\nI want to be involved in the community.\\n\\nI want to\"}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## text-generation\n",
    "text_generation = pipeline(\"text-generation\")\n",
    "text_generation(raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3389974",
   "metadata": {},
   "source": [
    "### Accessing Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e95ee53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad6d16ff7fa45b1a3872fd08e68c8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\") ## text classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d80f779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2026,  2171,  2003,  2019, 23049,  9600,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0],\n",
       "        [  101,  1045, 10587,  5114,  1996, 11532,  1999,  1996,  2492,  1997,\n",
       "          9932,  1013, 19875,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_inputs, return_tensors='pt', padding=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81c59b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-3.0620,  3.4210],\n",
       "        [ 2.2146, -2.0110]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c715b4e",
   "metadata": {},
   "source": [
    "### Model Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cc898a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455a631f2a9844a0945d23e05d2de7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DistilBertModel LOAD REPORT from: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "Key                   | Status     |  | \n",
      "----------------------+------------+--+-\n",
      "pre_classifier.bias   | UNEXPECTED |  | \n",
      "pre_classifier.weight | UNEXPECTED |  | \n",
      "classifier.bias       | UNEXPECTED |  | \n",
      "classifier.weight     | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "inputs = tokenizer(raw_inputs, return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "outputs.last_hidden_state.shape ## the token embeddings\n",
    "# torch.Size([2, 15, 768]) \n",
    "# 2 -> number of sentence\n",
    "# 15 -> input_ids size\n",
    "# 768 -> dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0715132c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to get the full context vector for the sequence\n",
    "context_vectors = outputs.last_hidden_state.mean(dim=1)\n",
    "context_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1a31838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"add_cross_attention\": false,\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"pad_token_id\": null,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"transformers_version\": \"5.0.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Accessing Model Config & Creating Custom Models\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "config = GPT2Config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "984c55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the model from the config\n",
    "gpt_model = GPT2Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11539882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f2b777fb6841f784cfff44c30bdbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## saving new model we created from config\n",
    "gpt_model.save_pretrained(\"/content/drive/MyDrive/gpt2_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4c5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
